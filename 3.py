import requests
import time
from datetime import datetime
import os

# === ì„¤ì •ê°’ ===
BASE_DATE = datetime.today().strftime("%Y-%m-%d")
MAX_PAGES = 1
DELAY = 0.5
INTERVAL = 300

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/91.0.4472.124 Safari/537.36"
    )
}

NEWS_FILE = "sdcard/news/news.txt"

def fetch_news(base_date=BASE_DATE, max_pages=MAX_PAGES, delay=DELAY):
    """ë„¤ì´ë²„ ë¶€ë™ì‚° ë‰´ìŠ¤ í¬ë¡¤ë§ í•¨ìˆ˜"""
    all_articles = []

    for page in range(1, max_pages + 1):
        url = f"https://land.naver.com/news/airsList.naver?baseDate={base_date}&page={page}&size=5"
        try:
            response = requests.get(url, headers=HEADERS, timeout=10)
            response.raise_for_status()
            data = response.json()
        except Exception as e:
            print(f"âš ï¸ {page} í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {e}")
            break

        if not data or not data.get("list"):
            break

        articles = [
            {
                "date": a.get("publishDateTime", "")[:10],
                "title": a.get("title", ""),
                "link": a.get("linkUrl", ""),
                "summary": (a.get("summaryContent", "").split(".")[0] + ".") if a.get("summaryContent") else "",
            }
            for a in data.get("list", [])
        ]
        all_articles.extend(articles)
        time.sleep(delay)

    return all_articles

def load_seen_links():
    if os.path.exists(NEWS_FILE):
        with open(NEWS_FILE, "r", encoding="utf-8") as f:
            return set(line.strip() for line in f if line.strip())
    return set()

def save_seen_links(seen_links):
    with open(NEWS_FILE, "w", encoding="utf-8") as f:
        f.writelines(link + "\n" for link in seen_links)

def main_loop():
    seen_links = load_seen_links()

    while True:
        print(f"\nâ° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} í¬ë¡¤ë§ ì‹œì‘")
        news = fetch_news()
        new_articles = [n for n in news if n["link"] and n["link"] not in seen_links]

        if new_articles:
            print(f"ğŸ†• ìƒˆ ë‰´ìŠ¤ {len(new_articles)}ê±´ ë°œê²¬!")
            for n in new_articles:
                print(f"- {n['date']} | {n['title']} ({n['link']})")
                seen_links.add(n["link"])
            save_seen_links(seen_links)
        else:
            print("ìƒˆë¡œìš´ ë‰´ìŠ¤ ì—†ìŒ.")

        print(f"ğŸ’¤ {INTERVAL/60}ë¶„ ëŒ€ê¸°...")
        time.sleep(INTERVAL)

if __name__ == "__main__":
    main_loop()
